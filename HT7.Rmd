---
title: "HT6-RegresionLogistica"
author: "AndresQuinto 18288, MirkaNicolle 18139, OscarDeLeon 19298"
date: "26/4/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Librerias que vamos a utilizar para la HT7
library(dplyr)
library(tidyr)
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
library(dplyr)
library(tidyr)
library(cluster)
library(e1071)
library(mclust)
library(fpc)
library(NbClust)
library(factoextra)
library(cluster)
library(e1071)
library(mclust)
library(fpc)
library(NbClust)
library(factoextra)
library(rpart)
library(corrplot)
library(dummies)
library(PerformanceAnalytics)
library(tictoc)
```

```{r}
# Analisis Exploratorio
train<- read.csv("train.csv", stringsAsFactors = FALSE)
test<- read.csv("test.csv", stringsAsFactors = FALSE)
train<-train[1:1460,]

glimpse(train[1:10,])

# Separacion de datos para training y testing, donde se deja el 70% para training y el 30% para testing
porcentaje<-0.7
datos<-read.csv("train.csv", stringsAsFactors = FALSE)
set.seed(123)

corte <- sample(nrow(datos),nrow(datos)*porcentaje)
train<-datos[corte,]
test<-datos[-corte,]

# Revisamos el tipo de datos del conjunto de entrenamiento
head(train)

# Revisamos el tipo de datos del conjunto de test
head(test)

glimpse(train[1:10,])
scatter.smooth(train$LotFrontage, train$SalePrice)
scatter.smooth(train$LotArea, train$SalePrice)
scatter.smooth(train$GrLivArea, train$SalePrice)
scatter.smooth(train$YearBuilt, train$SalePrice)
scatter.smooth(train$BsmtUnfSF, train$SalePrice)
scatter.smooth(train$TotalBsmtSF, train$SalePrice)
scatter.smooth(train$X1stFlrSF, train$SalePrice)
scatter.smooth(train$GarageYrBlt, train$SalePrice)
scatter.smooth(train$GarageArea, train$SalePrice)
scatter.smooth(train$YearRemodAdd, train$SalePrice)
scatter.smooth(train$TotRmsAbvGrd, train$SalePrice)
scatter.smooth(train$MoSold, train$SalePrice)
scatter.smooth(train$OverallQual, train$SalePrice)
```

Explore los datos y explique las transformaciones que debe hacerle para generar un modelo de máquinas vectoriales de soporte.

Use como variable respuesta la variable categórica que especifica si la casa es barata, media o cara

Genere varios (más de 2) modelos de SVM con diferentes kernels y distintos valores en los parámetros c, gamma y d (en caso de que utilice el polinomial).

Use los modelos para predecir el valor de la variable respuesta

Haga las matrices de confusión respectivas

Compare  los  resultados  obtenidos  con  los  diferentes  modelos  que  hizo  en  cuanto  a efectividad,  tiempo  de  procesamiento  y  equivocaciones  (donde  el  algoritmo se  equivocó más, donde se equivocó menos y la importancia que tienen los errores)

Compare  la  eficiencia  del  mejor  modelo  de  SVM  con  los  resultados  obtenidos  en  los algoritmos de las hojas de trabajo anteriores que usen la misma variable respuesta (árbol de decisión y random forest, naive bayes). ¿Cuál es mejor para predecir? ¿Cuál se demoró más en procesar?

Genere un informe de los resultados y las explicaciones
